{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3726bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from IPython.display import IFrame\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from netwerk import Netwerk\n",
    "from activatie_functies import ActivatieFuncties\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a843b0",
   "metadata": {},
   "source": [
    "## P1.1, 1.3, 1.4: opzet netwerk\n",
    "\n",
    "Voor het netwerk heb ik gekozen om in plaats van elke neuron een object te maken, gewoon alle weights en biases in matrices en vectoren te zetten, respectievelijk. Een netwerk evalueren aan de hand van een input vector werkt als volgt:\n",
    "\n",
    "$${g(x):= f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x+b^{1})\\cdots )+b^{L-1})+b^{L})}$$\n",
    "waarbij:\n",
    " - $x:$ input vector\n",
    " - $L:$ aantal layers\n",
    " - $W^{l}=(w_{jk}^{l}):$ matrix van weights tussen layer $l$ en $l-1$, waarbij $w_{jk}^{l}$ de weight tussen node $j$ in layer $l$ en node $k$ in layer $l-1$ \n",
    " - $b^{l}:$ bias vector van layer $l$\n",
    " - $f^{l}(x):$ activatiefunctie van layer $l$\n",
    " \n",
    "dit kunnen wij versimpelen door de bias vector aan het respectievelijke weight matrix te plakken en een 1 aan de input; een  bias is immers gewoon een weight die altijd geactiveerd wordt.\n",
    "het netwerk wordt dus geëvalueert dmv:\n",
    "\n",
    "$${g(x):= f^{L}((W^{L}|b^{L})f^{L-1}((W^{L-1}|b^{L-1})\\cdots f^{1}((W^{1}|b^{1})(x|1))\\cdots )))}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62202726",
   "metadata": {},
   "source": [
    "## P1.2: perceptron test\n",
    "\n",
    "een perceptron is praktisch gewoon een netwerk met maar een layer met een enkele neuron met de `step` als activatiefunctie.\n",
    "enkele gates als voorbeeld voor de functionaliteit van de perceptron hieronder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1c74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_in_2 = np.array(list(itertools.product([0, 1], repeat=1)))\n",
    "\n",
    "table_in_4   = np.array(list(itertools.product([0, 1], repeat=2)))\n",
    "\n",
    "table_in_8   = np.array(list(itertools.product([0, 1], repeat=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f78c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table AND\n",
      "[0 0] -> [0]\n",
      "[0 1] -> [0]\n",
      "[1 0] -> [0]\n",
      "[1 1] -> [1]\n",
      "\n",
      "truth table OR\n",
      "[0 0] -> [0]\n",
      "[0 1] -> [1]\n",
      "[1 0] -> [1]\n",
      "[1 1] -> [1]\n",
      "\n",
      "truth table NOT\n",
      "[0] -> [1]\n",
      "[1] -> [0]\n",
      "\n",
      "truth table NOR w/ 3 in\n",
      "[0 0 0] -> [1]\n",
      "[0 0 1] -> [0]\n",
      "[0 1 0] -> [0]\n",
      "[0 1 1] -> [0]\n",
      "[1 0 0] -> [0]\n",
      "[1 0 1] -> [0]\n",
      "[1 1 0] -> [0]\n",
      "[1 1 1] -> [0]\n",
      "\n",
      "truth table NAND w/ 3 in\n",
      "[0 0 0] -> [0]\n",
      "[0 0 1] -> [1]\n",
      "[0 1 0] -> [1]\n",
      "[0 1 1] -> [1]\n",
      "[1 0 0] -> [1]\n",
      "[1 0 1] -> [1]\n",
      "[1 1 0] -> [1]\n",
      "[1 1 1] -> [1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"434\"\n",
       "            height=\"329\"\n",
       "            src=\"./graphviz_renders/NAND.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a96cef2c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.STEP)\n",
    "\n",
    "netw._weights = [np.array([[ 1, 1,-2]])]\n",
    "print(\"truth table AND\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 1, 1,-1]])]\n",
    "print(\"\\ntruth table OR\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[-1, 0]])]\n",
    "print(\"\\ntruth table NOT\")\n",
    "for x in table_in_2:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "\n",
    "netw._weights = [np.array([[-1,-1,-1, 0]])]\n",
    "print(\"\\ntruth table NOR w/ 3 in\")\n",
    "for x in table_in_8:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 1, 1, 1,-1]])]\n",
    "print(\"\\ntruth table NAND w/ 3 in\")\n",
    "for x in table_in_8:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2', 'x3']), mindiam=.5, minlen=3, titel='NAND-gate perceptron', filename='NAND')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/NAND.gv.bmp')\n",
    "IFrame('./graphviz_renders/NAND.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5cb67",
   "metadata": {},
   "source": [
    "## P1.5: netwerk test\n",
    "\n",
    "Om het perceptron netwerk te demonstreren hieronder een netwerk met de functionaliteit van een half-adder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a9c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table XOR\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "\n",
      "truth table half-adder: \n",
      "[0 0] -> [0 0]\n",
      "[0 1] -> [0 1]\n",
      "[1 0] -> [0 1]\n",
      "[1 1] -> [1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"927\"\n",
       "            height=\"623\"\n",
       "            src=\"./graphviz_renders/HalfAdder.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a96cdec610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#`weights` en `biases` is private dus dit mag eigenlijk niet, maar je zou in het echt toch nooit \n",
    "                            #zelf de weights en biases zetten\n",
    "\n",
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.STEP)\n",
    "netw._weights = [np.array([[ 1, 1,-2],\n",
    "                           [ 1, 1,-1],\n",
    "                           [-1,-1, 1]]),\n",
    "                 np.array([[ 1, 0, 0,-1],\n",
    "                           [ 0, 1, 1,-2]])]\n",
    "\n",
    "print(\"truth table XOR\") #een XOR is eigenlijk gewoon het sum gedeelte van een half-adder, dus alleen dat gedeelte van\n",
    "                         #de output van de half-adder nemen resulteert in de truth table van een XOR\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)[1]))\n",
    "\n",
    "print(\"\\ntruth table half-adder: \")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2']), mindiam=1.2, minlen=4, titel='Half-adder perceptron netwerk', filename='HalfAdder')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/HalfAdder.gv.bmp')\n",
    "IFrame('./graphviz_renders/HalfAdder.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534b9d4",
   "metadata": {},
   "source": [
    "## P2.1: update\n",
    "\n",
    "Voor deze opdracht heb ik de functie `update_trivial` gemaakt, die één enkele layer updated aan de hand van:\n",
    "$$Δw_j = η (target^{(i)} – output^{(i)}) x_j^{(i)}$$\n",
    "Wat in onze enkele layer dus neerkomt op:\n",
    "$$W_1 = W_0 + η (target^{(i)} – f(W_0in^{(i)}))⊗_{outer}in^{(i)}$$\n",
    "waarbij:\n",
    " - $W_n:$ matrix van weights (incl. biases) na update n \n",
    " - $η:$ learning rate\n",
    " - $target^{(i)}:$ target feature i \n",
    " - $in^{(i)}:$ input feature i (incl. 1 voor bias)\n",
    " - $f(x):$ activatiefunctie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285810cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
