{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3726bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from IPython.display import IFrame\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from netwerk import Netwerk\n",
    "from activatie_functies import ActivatieFuncties\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a843b0",
   "metadata": {},
   "source": [
    "## P1.1, 1.3, 1.4: opzet netwerk\n",
    "\n",
    "Voor het netwerk heb ik gekozen om in plaats van elke neuron een object te maken, gewoon alle weights en biases in matrices en vectoren te zetten, respectievelijk. Een netwerk evalueren aan de hand van een input vector werkt als volgt:\n",
    "\n",
    "$${g(x):= f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x+b^{1})\\cdots )+b^{L-1})+b^{L})}$$\n",
    "waarbij:\n",
    " - $x:$ input vector\n",
    " - $L:$ aantal layers\n",
    " - $W^{l}=(w_{jk}^{l}):$ matrix van weights tussen layer $l$ en $l-1$, waarbij $w_{jk}^{l}$ de weight tussen node $j$ in layer $l$ en node $k$ in layer $l-1$ \n",
    " - $b^{l}:$ bias vector van layer $l$\n",
    " - $f^{l}(x):$ activatiefunctie van layer $l$\n",
    " \n",
    "dit kunnen wij versimpelen door de bias vector aan het respectievelijke weight matrix te plakken en een 1 aan de input; een  bias is immers gewoon een weight die altijd geactiveerd wordt.\n",
    "het netwerk wordt dus geëvalueert dmv:\n",
    "\n",
    "$${g(x):= f^{L}((W^{L}|b^{L})f^{L-1}((W^{L-1}|b^{L-1})\\cdots f^{1}((W^{1}|b^{1})(x|1))\\cdots )))}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62202726",
   "metadata": {},
   "source": [
    "## P1.2: perceptron test\n",
    "\n",
    "een perceptron is praktisch gewoon een netwerk met maar een layer met een enkele neuron met de `step` als activatiefunctie.\n",
    "enkele gates als voorbeeld voor de functionaliteit van de perceptron hieronder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1c74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_in_2 = np.array(list(itertools.product([0, 1], repeat=1)))\n",
    "\n",
    "table_in_4   = np.array(list(itertools.product([0, 1], repeat=2)))\n",
    "\n",
    "table_in_8   = np.array(list(itertools.product([0, 1], repeat=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f78c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table AND\n",
      "[0 0] -> [[0]]\n",
      "[0 1] -> [[0]]\n",
      "[1 0] -> [[0]]\n",
      "[1 1] -> [[1]]\n",
      "\n",
      "truth table OR\n",
      "[0 0] -> [[0]]\n",
      "[0 1] -> [[1]]\n",
      "[1 0] -> [[1]]\n",
      "[1 1] -> [[1]]\n",
      "\n",
      "truth table NOT\n",
      "[0] -> [[1]]\n",
      "[1] -> [[0]]\n",
      "\n",
      "truth table NOR w/ 3 in\n",
      "[0 0 0] -> [[1]]\n",
      "[0 0 1] -> [[0]]\n",
      "[0 1 0] -> [[0]]\n",
      "[0 1 1] -> [[0]]\n",
      "[1 0 0] -> [[0]]\n",
      "[1 0 1] -> [[0]]\n",
      "[1 1 0] -> [[0]]\n",
      "[1 1 1] -> [[0]]\n",
      "\n",
      "truth table NAND w/ 3 in\n",
      "[0 0 0] -> [[0]]\n",
      "[0 0 1] -> [[1]]\n",
      "[0 1 0] -> [[1]]\n",
      "[0 1 1] -> [[1]]\n",
      "[1 0 0] -> [[1]]\n",
      "[1 0 1] -> [[1]]\n",
      "[1 1 0] -> [[1]]\n",
      "[1 1 1] -> [[1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"434\"\n",
       "            height=\"329\"\n",
       "            src=\"./graphviz_renders/NAND.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18dff57d040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.STEP)\n",
    "\n",
    "netw._weights = [np.array([[ 1, 1,-2]])]\n",
    "print(\"truth table AND\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 1, 1,-1]])]\n",
    "print(\"\\ntruth table OR\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[-1, 0]])]\n",
    "print(\"\\ntruth table NOT\")\n",
    "for x in table_in_2:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "\n",
    "netw._weights = [np.array([[-1,-1,-1, 0]])]\n",
    "print(\"\\ntruth table NOR w/ 3 in\")\n",
    "for x in table_in_8:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 1, 1, 1,-1]])]\n",
    "print(\"\\ntruth table NAND w/ 3 in\")\n",
    "for x in table_in_8:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2', 'x3']), mindiam=.5, minlen=3, titel='NAND-gate perceptron', filename='NAND')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/NAND.gv.bmp')\n",
    "IFrame('./graphviz_renders/NAND.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5cb67",
   "metadata": {},
   "source": [
    "## P1.5: netwerk test\n",
    "\n",
    "Om het perceptron netwerk te demonstreren hieronder een netwerk met de functionaliteit van een half-adder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a9c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table XOR\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "\n",
      "truth table half-adder: \n",
      "[0 0] -> [[0 0]]\n",
      "[0 1] -> [[0 1]]\n",
      "[1 0] -> [[0 1]]\n",
      "[1 1] -> [[1 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"927\"\n",
       "            height=\"623\"\n",
       "            src=\"./graphviz_renders/HalfAdder.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18dff594e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#`weights` en `biases` is private dus dit mag eigenlijk niet, maar je zou in het echt toch nooit \n",
    "                            #zelf de weights en biases zetten\n",
    "\n",
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.STEP)\n",
    "netw._weights = [np.array([[ 1, 1,-2],\n",
    "                           [ 1, 1,-1],\n",
    "                           [-1,-1, 1]]),\n",
    "                 np.array([[ 1, 0, 0,-1],\n",
    "                           [ 0, 1, 1,-2]])]\n",
    "\n",
    "print(\"truth table XOR\") #een XOR is eigenlijk gewoon het sum gedeelte van een half-adder, dus alleen dat gedeelte van\n",
    "                         #de output van de half-adder nemen resulteert in de truth table van een XOR\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)[0][1]))\n",
    "\n",
    "print(\"\\ntruth table half-adder: \")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2']), mindiam=1.2, minlen=4, titel='Half-adder perceptron netwerk', filename='HalfAdder')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/HalfAdder.gv.bmp')\n",
    "IFrame('./graphviz_renders/HalfAdder.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534b9d4",
   "metadata": {},
   "source": [
    "## P2: Perceptron learning rule\n",
    "\n",
    "Voor deze opdracht heb ik de functie `update_trivial` gemaakt, die één enkele layer updated aan de hand van:\n",
    "$$Δw_j = η (target^{(i)} – output^{(i)}) x_j^{(i)}$$\n",
    "Wat in onze enkele layer dus neerkomt op:\n",
    "$$W_1 = W_0 + η (target^{(i)} – f(W_0in^{(i)}))⊗_{outer}in^{(i)}$$\n",
    "waarbij:\n",
    " - $W_n:$ matrix van weights (incl. biases) na update n \n",
    " - $η:$ learning rate\n",
    " - $target^{(i)}:$ target feature i \n",
    " - $in^{(i)}:$ input feature i (incl. 1 voor bias)\n",
    " - $f(x):$ activatiefunctie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a93c6c",
   "metadata": {},
   "source": [
    "## P2.3 a: AND \n",
    "hieronder de learning rule gedemonstreerd door een perceptron de AND-gate te leren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285810cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial weights:\n",
      "[[-1.34322705  0.53339359  1.04945582]]\n",
      "initial MSE:\n",
      "[0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.8 0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.8 0.8]]\n",
      "updated W = \n",
      "[[[0.25677295 1.33339359 0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[ 0.25677295  1.33339359 -0.55054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[ 0.25677295  0.53339359 -1.35054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[ 0.25677295  0.53339359 -1.35054418]]]\n",
      "MSE       = [0.25]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.8 0.8]]\n",
      "updated W = \n",
      "[[[ 1.05677295  1.33339359 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[ 1.05677295  1.33339359 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[ 1.05677295  0.53339359 -1.35054418]]]\n",
      "MSE       = [0.]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[ 1.05677295  0.53339359 -1.35054418]]]\n",
      "MSE       = [0.]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[ 1.05677295  0.53339359 -1.35054418]]]\n",
      "MSE       = [0.]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"535\"\n",
       "            height=\"218\"\n",
       "            src=\"./graphviz_renders/learningRule.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18d83c98520>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1819772)\n",
    "netw = Netwerk(0, 0, 2, 1, ActivatieFuncties.STEP, .8)\n",
    "\n",
    "d_and = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "print(\"\\ninitial weights:\")\n",
    "for w in netw._weights:\n",
    "    print(w)\n",
    "print(\"initial MSE:\")\n",
    "print(netw.loss_MSE(table_in_4, d_and))\n",
    "print()\n",
    "\n",
    "for i in range(4):\n",
    "    netw.update_trivial(table_in_4, d_and, True)\n",
    "\n",
    "g1 = netw.visualise_network(np.array(['x1', 'x2']), mindiam=.5, minlen=5, filename='learningRule')\n",
    "g1.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/learningRule.gv.bmp')\n",
    "IFrame('./graphviz_renders/learningRule.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c73b81f",
   "metadata": {},
   "source": [
    "## P2.3 b: XOR\n",
    "een enkele perceptron kan nooit een XOR-gate leren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706068e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial weights:\n",
      "[[-1.34322705  0.53339359  1.04945582]]\n",
      "initial MSE:\n",
      "[0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0. 0. 0.]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.  -0.  -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641 -0.55054418]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.  0.8 0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705  0.53339359  0.24945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[0.8 0.  0.8]]\n",
      "updated W = \n",
      "[[[-0.54322705  0.53339359  1.04945582]]]\n",
      "MSE       = [0.5]\n",
      "\n",
      "Δ ⊗ in    = \n",
      "[[-0.8 -0.8 -0.8]]\n",
      "updated W = \n",
      "[[[-1.34322705 -0.26660641  0.24945582]]]\n",
      "MSE       = [0.75]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"535\"\n",
       "            height=\"218\"\n",
       "            src=\"./graphviz_renders/learningRule.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18dff56f040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1819772)\n",
    "netw = Netwerk(0, 0, 2, 1, ActivatieFuncties.STEP, .8)\n",
    "\n",
    "d_xor = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "print(\"\\ninitial weights:\")\n",
    "for w in netw._weights:\n",
    "    print(w)\n",
    "print(\"initial MSE:\")\n",
    "print(netw.loss_MSE(table_in_4, d_xor))\n",
    "print()\n",
    "\n",
    "for i in range(10):\n",
    "    netw.update_trivial(table_in_4, d_xor, True)\n",
    "\n",
    "g1 = netw.visualise_network(np.array(['x1', 'x2']), mindiam=.5, minlen=5, filename='learningRule')\n",
    "g1.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/learningRule.gv.bmp')\n",
    "IFrame('./graphviz_renders/learningRule.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df215a",
   "metadata": {},
   "source": [
    "## P2.3 c: Iris\n",
    "met alleen *Setosa* en *Versicolour* lijkt het gauw al volledig te werken, deze zijn immers vrij verschillend. Met *Versicolour* en *Verginica* duurt het wat langer voor de score verbetert, en komt op zn best rond de 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fcbbaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.6, 1.4, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = np.reshape(iris.target,(-1,1))\n",
    "np.c_[X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "032d6983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[[-0.64322705  0.85339359  1.51945582  1.16135062 -1.25814302]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.66322705  0.74339359  1.70945582  1.24135062 -1.25814302]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.57322705  0.61339359  1.96945582  1.32135062 -1.25814302]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.08322705  0.26339359  1.82945582  1.30135062 -1.35814302]]]\n",
      "loss:    [0.]\n",
      "weights: [[[-1.08322705  0.26339359  1.82945582  1.30135062 -1.35814302]]]\n",
      "loss:    [0.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1819772)\n",
    "netw = Netwerk(0, 0, 4, 1, ActivatieFuncties.STEP, .1)\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]\n",
    "y = np.reshape(iris.target[:100],(-1,1))\n",
    "\n",
    "for i in range(5):\n",
    "    netw.update_trivial(X, y, False)\n",
    "    print(\"weights: \" + str(netw._weights))\n",
    "    print(\"loss:    \" + str(netw.loss_MSE(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1411fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.76405235, 0.40015721, 0.97873798, 2.2408932 , 1.86755799]])]\n",
      "weights: [[[ 0.36405235 -0.21984279  0.16873798  2.0508932   1.66755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[ 0.37405235 -0.23984279  0.28873798  2.1208932   1.66755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.24594765 -0.45984279  0.01873798  2.1008932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.31594765 -0.44984279  0.14873798  2.2108932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.38594765 -0.43984279  0.27873798  2.3208932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.45594765 -0.42984279  0.40873798  2.4308932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.52594765 -0.41984279  0.53873798  2.5408932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.59594765 -0.40984279  0.66873798  2.6508932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.66594765 -0.39984279  0.79873798  2.7608932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.73594765 -0.38984279  0.92873798  2.8708932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.80594765 -0.37984279  1.05873798  2.9808932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.92594765 -0.42984279  1.09873798  3.0308932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-0.99594765 -0.41984279  1.22873798  3.1408932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.11594765 -0.46984279  1.26873798  3.1908932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.18594765 -0.45984279  1.39873798  3.3008932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.30594765 -0.50984279  1.43873798  3.3508932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.37594765 -0.49984279  1.56873798  3.4608932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.49594765 -0.54984279  1.60873798  3.5108932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.61594765 -0.59984279  1.64873798  3.5608932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.68594765 -0.58984279  1.77873798  3.6708932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-1.80594765 -0.63984279  1.81873798  3.7208932   1.56755799]]]\n",
      "loss:    [0.49]\n",
      "weights: [[[-1.87594765 -0.62984279  1.94873798  3.8308932   1.56755799]]]\n",
      "loss:    [0.49]\n",
      "weights: [[[-1.99594765 -0.67984279  1.98873798  3.8808932   1.56755799]]]\n",
      "loss:    [0.47]\n",
      "weights: [[[-2.06594765 -0.66984279  2.11873798  3.9908932   1.56755799]]]\n",
      "loss:    [0.49]\n",
      "weights: [[[-2.18594765 -0.71984279  2.15873798  4.0408932   1.56755799]]]\n",
      "loss:    [0.43]\n",
      "weights: [[[-2.24594765 -0.76984279  2.21873798  4.0808932   1.56755799]]]\n",
      "loss:    [0.39]\n",
      "weights: [[[-2.30594765 -0.81984279  2.27873798  4.1208932   1.56755799]]]\n",
      "loss:    [0.35]\n",
      "weights: [[[-2.36594765 -0.86984279  2.33873798  4.1608932   1.56755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-2.37594765 -0.85984279  2.48873798  4.2608932   1.56755799]]]\n",
      "loss:    [0.43]\n",
      "weights: [[[-2.43594765 -0.90984279  2.54873798  4.3008932   1.56755799]]]\n",
      "loss:    [0.4]\n",
      "weights: [[[-2.49594765 -0.95984279  2.60873798  4.3408932   1.56755799]]]\n",
      "loss:    [0.35]\n",
      "weights: [[[-2.55594765 -1.00984279  2.66873798  4.3808932   1.56755799]]]\n",
      "loss:    [0.33]\n",
      "weights: [[[-2.61594765 -1.05984279  2.72873798  4.4208932   1.56755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-2.67594765 -1.10984279  2.78873798  4.4608932   1.56755799]]]\n",
      "loss:    [0.29]\n",
      "weights: [[[-2.73594765 -1.15984279  2.84873798  4.5008932   1.56755799]]]\n",
      "loss:    [0.26]\n",
      "weights: [[[-2.70594765 -1.11984279  2.95873798  4.5608932   1.56755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-2.76594765 -1.16984279  3.01873798  4.6008932   1.56755799]]]\n",
      "loss:    [0.33]\n",
      "weights: [[[-2.82594765 -1.21984279  3.07873798  4.6408932   1.56755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-2.88594765 -1.26984279  3.13873798  4.6808932   1.56755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-2.94594765 -1.31984279  3.19873798  4.7208932   1.56755799]]]\n",
      "loss:    [0.26]\n",
      "weights: [[[-2.78594765 -1.24984279  3.38873798  4.8008932   1.56755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-2.77594765 -1.26984279  3.50873798  4.8708932   1.56755799]]]\n",
      "loss:    [0.49]\n",
      "weights: [[[-2.76594765 -1.28984279  3.62873798  4.9408932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-2.71594765 -1.24984279  3.82873798  5.0508932   1.56755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-3.34594765 -1.53984279  3.50873798  5.0108932   1.46755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-3.31594765 -1.49984279  3.61873798  5.0708932   1.46755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-3.15594765 -1.42984279  3.80873798  5.1508932   1.46755799]]]\n",
      "loss:    [0.44]\n",
      "weights: [[[-3.08594765 -1.44984279  3.94873798  5.2108932   1.46755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-3.05594765 -1.47984279  4.10873798  5.2508932   1.46755799]]]\n",
      "loss:    [0.49]\n",
      "weights: [[[-2.99594765 -1.48984279  4.33873798  5.3408932   1.46755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-3.67594765 -1.83984279  3.92873798  5.2408932   1.36755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-3.65594765 -1.86984279  3.98873798  5.2808932   1.36755799]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-3.64594765 -1.87984279  4.04873798  5.3408932   1.36755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-3.61594765 -1.83984279  4.15873798  5.4008932   1.36755799]]]\n",
      "loss:    [0.2]\n",
      "weights: [[[-3.45594765 -1.76984279  4.34873798  5.4808932   1.36755799]]]\n",
      "loss:    [0.39]\n",
      "weights: [[[-3.36594765 -1.79984279  4.52873798  5.5108932   1.36755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-3.31594765 -1.75984279  4.72873798  5.6208932   1.36755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-3.30594765 -1.82984279  4.86873798  5.6508932   1.36755799]]]\n",
      "loss:    [0.5]\n",
      "weights: [[[-3.98594765 -2.17984279  4.45873798  5.5508932   1.26755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-3.96594765 -2.20984279  4.51873798  5.5908932   1.26755799]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-3.95594765 -2.21984279  4.57873798  5.6508932   1.26755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-3.79594765 -2.14984279  4.76873798  5.7308932   1.26755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-3.72594765 -2.16984279  4.90873798  5.7908932   1.26755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-3.68594765 -2.10984279  5.05873798  5.9308932   1.26755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-3.63594765 -2.06984279  5.25873798  6.0408932   1.26755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-4.31594765 -2.41984279  4.84873798  5.9408932   1.16755799]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-4.29594765 -2.44984279  4.90873798  5.9808932   1.16755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-4.27594765 -2.47984279  4.96873798  6.0208932   1.16755799]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-4.26594765 -2.48984279  5.02873798  6.0808932   1.16755799]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-4.12594765 -2.46984279  5.16873798  6.1608932   1.16755799]]]\n",
      "loss:    [0.23]\n",
      "weights: [[[-4.02594765 -2.37984279  5.27873798  6.2308932   1.16755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-3.98594765 -2.31984279  5.42873798  6.3708932   1.16755799]]]\n",
      "loss:    [0.47]\n",
      "weights: [[[-3.93594765 -2.27984279  5.62873798  6.4808932   1.16755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-4.61594765 -2.62984279  5.21873798  6.3808932   1.06755799]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-4.59594765 -2.65984279  5.27873798  6.4208932   1.06755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-4.57594765 -2.68984279  5.33873798  6.4608932   1.06755799]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-4.42594765 -2.68984279  5.47873798  6.5208932   1.06755799]]]\n",
      "loss:    [0.19]\n",
      "weights: [[[-4.24594765 -2.62984279  5.70873798  6.5708932   1.06755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-4.13594765 -2.58984279  5.92873798  6.6708932   1.06755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-4.12594765 -2.65984279  6.06873798  6.7008932   1.06755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-4.80594765 -3.00984279  5.65873798  6.6008932   0.96755799]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-4.78594765 -3.03984279  5.71873798  6.6408932   0.96755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-4.63594765 -3.03984279  5.85873798  6.7008932   0.96755799]]]\n",
      "loss:    [0.15]\n",
      "weights: [[[-4.45594765 -2.97984279  6.08873798  6.7508932   0.96755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-4.44594765 -2.95984279  6.20873798  6.8708932   0.96755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-4.47594765 -3.04984279  6.26873798  6.9108932   0.96755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-4.48594765 -3.04984279  6.32873798  6.9908932   0.96755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-4.41594765 -3.11984279  6.48873798  7.0108932   0.96755799]]]\n",
      "loss:    [0.47]\n",
      "weights: [[[-4.40594765 -3.18984279  6.62873798  7.0408932   0.96755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-5.11594765 -3.55984279  6.18873798  6.9108932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.12594765 -3.60984279  6.21873798  6.9208932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.13594765 -3.65984279  6.24873798  6.9308932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.14594765 -3.70984279  6.27873798  6.9408932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.15594765 -3.75984279  6.30873798  6.9508932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.16594765 -3.80984279  6.33873798  6.9608932   0.86755799]]]\n",
      "loss:    [0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[[-5.17594765 -3.85984279  6.36873798  6.9708932   0.86755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-4.39594765 -3.52984279  7.03873798  7.1808932   0.96755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-4.94594765 -3.84984279  6.70873798  7.1008932   0.86755799]]]\n",
      "loss:    [0.15]\n",
      "weights: [[[-4.81594765 -3.69984279  6.90873798  7.2608932   0.86755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-4.82594765 -3.69984279  6.96873798  7.3408932   0.86755799]]]\n",
      "loss:    [0.32]\n",
      "weights: [[[-4.83594765 -3.69984279  7.02873798  7.4208932   0.86755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-4.76594765 -3.76984279  7.18873798  7.4408932   0.86755799]]]\n",
      "loss:    [0.4]\n",
      "weights: [[[-5.41594765 -4.13984279  6.76873798  7.3008932   0.76755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.42594765 -4.18984279  6.79873798  7.3108932   0.76755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.43594765 -4.23984279  6.82873798  7.3208932   0.76755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.44594765 -4.28984279  6.85873798  7.3308932   0.76755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-4.66594765 -3.95984279  7.52873798  7.5408932   0.86755799]]]\n",
      "loss:    [0.48]\n",
      "weights: [[[-5.21594765 -4.27984279  7.19873798  7.4608932   0.76755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-5.13594765 -4.18984279  7.30873798  7.5608932   0.76755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-5.05594765 -4.09984279  7.41873798  7.6608932   0.76755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-5.06594765 -4.09984279  7.47873798  7.7408932   0.76755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-4.99594765 -4.16984279  7.63873798  7.7608932   0.76755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-5.64594765 -4.53984279  7.21873798  7.6208932   0.66755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.65594765 -4.58984279  7.24873798  7.6308932   0.66755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.66594765 -4.63984279  7.27873798  7.6408932   0.66755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.67594765 -4.68984279  7.30873798  7.6508932   0.66755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-5.68594765 -4.73984279  7.33873798  7.6608932   0.66755799]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-4.90594765 -4.40984279  8.00873798  7.8708932   0.76755799]]]\n",
      "loss:    [0.47]\n",
      "weights: [[[-5.45594765 -4.72984279  7.67873798  7.7908932   0.66755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-5.37594765 -4.63984279  7.78873798  7.8908932   0.66755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-5.29594765 -4.54984279  7.89873798  7.9908932   0.66755799]]]\n",
      "loss:    [0.29]\n",
      "weights: [[[-5.35594765 -4.53984279  7.91873798  8.0708932   0.66755799]]]\n",
      "loss:    [0.29]\n",
      "weights: [[[-5.41594765 -4.52984279  7.93873798  8.1508932   0.66755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.47594765 -4.51984279  7.95873798  8.2308932   0.66755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.53594765 -4.50984279  7.97873798  8.3108932   0.66755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.59594765 -4.49984279  7.99873798  8.3908932   0.66755799]]]\n",
      "loss:    [0.25]\n",
      "weights: [[[-5.43594765 -4.47984279  8.20873798  8.4308932   0.66755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-5.95594765 -4.81984279  7.86873798  8.3108932   0.56755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-5.80594765 -4.81984279  8.00873798  8.3708932   0.56755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-5.72594765 -4.72984279  8.11873798  8.4708932   0.56755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-5.64594765 -4.63984279  8.22873798  8.5708932   0.56755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.70594765 -4.62984279  8.24873798  8.6508932   0.56755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.76594765 -4.61984279  8.26873798  8.7308932   0.56755799]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-5.82594765 -4.60984279  8.28873798  8.8108932   0.56755799]]]\n",
      "loss:    [0.25]\n",
      "weights: [[[-5.66594765 -4.58984279  8.49873798  8.8508932   0.56755799]]]\n",
      "loss:    [0.36]\n",
      "weights: [[[-6.18594765 -4.92984279  8.15873798  8.7308932   0.46755799]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-6.01594765 -4.93984279  8.33873798  8.7608932   0.46755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-5.93594765 -4.84984279  8.44873798  8.8608932   0.46755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-5.77594765 -4.82984279  8.65873798  8.9008932   0.46755799]]]\n",
      "loss:    [0.31]\n",
      "weights: [[[-6.29594765 -5.16984279  8.31873798  8.7808932   0.36755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.14594765 -5.16984279  8.45873798  8.8408932   0.36755799]]]\n",
      "loss:    [0.11]\n",
      "weights: [[[-6.06594765 -5.07984279  8.56873798  8.9408932   0.36755799]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-5.98594765 -4.98984279  8.67873798  9.0408932   0.36755799]]]\n",
      "loss:    [0.23]\n",
      "weights: [[[-6.41594765 -5.23984279  8.38873798  8.9408932   0.26755799]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-6.32594765 -5.15984279  8.52873798  9.0008932   0.26755799]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.23594765 -5.13984279  8.58873798  9.0508932   0.26755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.15594765 -5.04984279  8.69873798  9.1508932   0.26755799]]]\n",
      "loss:    [0.19]\n",
      "weights: [[[-6.07594765 -4.95984279  8.80873798  9.2508932   0.26755799]]]\n",
      "loss:    [0.26]\n",
      "weights: [[[-6.13594765 -4.94984279  8.82873798  9.3308932   0.26755799]]]\n",
      "loss:    [0.24]\n",
      "weights: [[[-6.56594765 -5.19984279  8.53873798  9.2308932   0.16755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.41594765 -5.19984279  8.67873798  9.2908932   0.16755799]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-6.33594765 -5.15984279  8.73873798  9.3608932   0.16755799]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.25594765 -5.06984279  8.84873798  9.4608932   0.16755799]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-6.09594765 -5.04984279  9.05873798  9.5008932   0.16755799]]]\n",
      "loss:    [0.3]\n",
      "weights: [[[-6.61594765 -5.38984279  8.71873798  9.3808932   0.06755799]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.44594765 -5.39984279  8.89873798  9.4108932   0.06755799]]]\n",
      "loss:    [0.11]\n",
      "weights: [[[-6.36594765 -5.30984279  9.00873798  9.5108932   0.06755799]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-6.28594765 -5.21984279  9.11873798  9.6108932   0.06755799]]]\n",
      "loss:    [0.22]\n",
      "weights: [[[-6.71594765 -5.46984279  8.82873798  9.5108932  -0.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-6.62594765 -5.38984279  8.96873798  9.5708932  -0.03244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.53594765 -5.36984279  9.02873798  9.6208932  -0.03244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.45594765 -5.27984279  9.13873798  9.7208932  -0.03244201]]]\n",
      "loss:    [0.18]\n",
      "weights: [[[-6.29594765 -5.25984279  9.34873798  9.7608932  -0.03244201]]]\n",
      "loss:    [0.28]\n",
      "weights: [[[-6.86594765 -5.58984279  8.96873798  9.6408932  -0.13244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-6.74594765 -5.60984279  9.07873798  9.6708932  -0.13244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.65594765 -5.58984279  9.13873798  9.7208932  -0.13244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-6.59594765 -5.54984279  9.19873798  9.8208932  -0.13244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.51594765 -5.45984279  9.30873798  9.9208932  -0.13244201]]]\n",
      "loss:    [0.19]\n",
      "weights: [[[-6.94594765 -5.70984279  9.01873798  9.8208932  -0.23244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-6.82594765 -5.72984279  9.12873798  9.8508932  -0.23244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.73594765 -5.70984279  9.18873798  9.9008932  -0.23244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.64594765 -5.68984279  9.24873798  9.9508932  -0.23244201]]]\n",
      "loss:    [0.11]\n",
      "weights: [[[-6.56594765 -5.59984279  9.35873798 10.0508932  -0.23244201]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-6.41594765 -5.52984279  9.53873798 10.1108932  -0.23244201]]]\n",
      "loss:    [0.26]\n",
      "weights: [[[-6.98594765 -5.85984279  9.15873798  9.9908932  -0.33244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-6.86594765 -5.87984279  9.26873798 10.0208932  -0.33244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.77594765 -5.85984279  9.32873798 10.0708932  -0.33244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.70594765 -5.83984279  9.38873798 10.1508932  -0.33244201]]]\n",
      "loss:    [0.11]\n",
      "weights: [[[-6.62594765 -5.74984279  9.49873798 10.2508932  -0.33244201]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-7.06594765 -5.94984279  9.17873798 10.1708932  -0.43244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-6.94594765 -5.96984279  9.28873798 10.2008932  -0.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-6.91594765 -5.86984279  9.34873798 10.2508932  -0.43244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.82594765 -5.84984279  9.40873798 10.3008932  -0.43244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-6.76594765 -5.80984279  9.46873798 10.4008932  -0.43244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.68594765 -5.71984279  9.57873798 10.5008932  -0.43244201]]]\n",
      "loss:    [0.19]\n",
      "weights: [[[-7.11594765 -5.96984279  9.28873798 10.4008932  -0.53244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-6.99594765 -5.98984279  9.39873798 10.4308932  -0.53244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-6.90594765 -5.96984279  9.45873798 10.4808932  -0.53244201]]]\n",
      "loss:    [0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[[-6.83594765 -5.94984279  9.51873798 10.5608932  -0.53244201]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-6.77594765 -5.90984279  9.57873798 10.6608932  -0.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.69594765 -5.81984279  9.68873798 10.7608932  -0.53244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-7.12594765 -6.06984279  9.39873798 10.6608932  -0.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.01594765 -5.99984279  9.57873798 10.6908932  -0.63244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.94594765 -5.97984279  9.63873798 10.7708932  -0.63244201]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-6.88594765 -5.93984279  9.69873798 10.8708932  -0.63244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.60594765 -5.83984279  9.95873798 10.9508932  -0.63244201]]]\n",
      "loss:    [0.28]\n",
      "weights: [[[-7.17594765 -6.16984279  9.57873798 10.8308932  -0.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.14594765 -6.06984279  9.63873798 10.8808932  -0.73244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.05594765 -6.04984279  9.69873798 10.9308932  -0.73244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-6.98594765 -6.02984279  9.75873798 11.0108932  -0.73244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.90594765 -5.93984279  9.86873798 11.1108932  -0.73244201]]]\n",
      "loss:    [0.18]\n",
      "weights: [[[-7.33594765 -6.18984279  9.57873798 11.0108932  -0.83244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-7.21594765 -6.20984279  9.68873798 11.0408932  -0.83244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.12594765 -6.18984279  9.74873798 11.0908932  -0.83244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.05594765 -6.16984279  9.80873798 11.1708932  -0.83244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-6.99594765 -6.12984279  9.86873798 11.2708932  -0.83244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.71594765 -6.02984279 10.12873798 11.3508932  -0.83244201]]]\n",
      "loss:    [0.28]\n",
      "weights: [[[-7.28594765 -6.35984279  9.74873798 11.2308932  -0.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.25594765 -6.25984279  9.80873798 11.2808932  -0.93244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.16594765 -6.23984279  9.86873798 11.3308932  -0.93244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.09594765 -6.21984279  9.92873798 11.4108932  -0.93244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.81594765 -6.11984279 10.18873798 11.4908932  -0.93244201]]]\n",
      "loss:    [0.25]\n",
      "weights: [[[-7.38594765 -6.44984279  9.80873798 11.3708932  -1.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.35594765 -6.34984279  9.86873798 11.4208932  -1.03244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.26594765 -6.32984279  9.92873798 11.4708932  -1.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.19594765 -6.30984279  9.98873798 11.5508932  -1.03244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-7.13594765 -6.26984279 10.04873798 11.6508932  -1.03244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-6.85594765 -6.16984279 10.30873798 11.7308932  -1.03244201]]]\n",
      "loss:    [0.27]\n",
      "weights: [[[-7.42594765 -6.49984279  9.92873798 11.6108932  -1.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.39594765 -6.39984279  9.98873798 11.6608932  -1.13244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.32594765 -6.37984279 10.04873798 11.7408932  -1.13244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.25594765 -6.35984279 10.10873798 11.8208932  -1.13244201]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-6.97594765 -6.25984279 10.36873798 11.9008932  -1.13244201]]]\n",
      "loss:    [0.23]\n",
      "weights: [[[-7.49594765 -6.38984279 10.02873798 11.8208932  -1.23244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.40594765 -6.36984279 10.08873798 11.8708932  -1.23244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.33594765 -6.34984279 10.14873798 11.9508932  -1.23244201]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-7.27594765 -6.30984279 10.20873798 12.0508932  -1.23244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-7.70594765 -6.55984279  9.91873798 11.9508932  -1.33244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-7.58594765 -6.57984279 10.02873798 11.9808932  -1.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.55594765 -6.47984279 10.08873798 12.0308932  -1.33244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.46594765 -6.45984279 10.14873798 12.0808932  -1.33244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.39594765 -6.43984279 10.20873798 12.1608932  -1.33244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-7.33594765 -6.39984279 10.26873798 12.2608932  -1.33244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-7.76594765 -6.64984279  9.97873798 12.1608932  -1.43244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-7.64594765 -6.66984279 10.08873798 12.1908932  -1.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.61594765 -6.56984279 10.14873798 12.2408932  -1.43244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.52594765 -6.54984279 10.20873798 12.2908932  -1.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.45594765 -6.52984279 10.26873798 12.3708932  -1.43244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-7.39594765 -6.48984279 10.32873798 12.4708932  -1.43244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-7.11594765 -6.38984279 10.58873798 12.5508932  -1.43244201]]]\n",
      "loss:    [0.25]\n",
      "weights: [[[-7.66594765 -6.72984279 10.24873798 12.4008932  -1.53244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.57594765 -6.70984279 10.30873798 12.4508932  -1.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.50594765 -6.68984279 10.36873798 12.5308932  -1.53244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.43594765 -6.66984279 10.42873798 12.6108932  -1.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-7.15594765 -6.56984279 10.68873798 12.6908932  -1.53244201]]]\n",
      "loss:    [0.25]\n",
      "weights: [[[-7.70594765 -6.90984279 10.34873798 12.5408932  -1.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.67594765 -6.80984279 10.40873798 12.5908932  -1.63244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.60594765 -6.78984279 10.46873798 12.6708932  -1.63244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.53594765 -6.76984279 10.52873798 12.7508932  -1.63244201]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-7.25594765 -6.66984279 10.78873798 12.8308932  -1.63244201]]]\n",
      "loss:    [0.23]\n",
      "weights: [[[-7.77594765 -6.79984279 10.44873798 12.7508932  -1.73244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.70594765 -6.77984279 10.50873798 12.8308932  -1.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.63594765 -6.75984279 10.56873798 12.9108932  -1.73244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-7.37594765 -6.70984279 10.77873798 12.9908932  -1.73244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-7.86594765 -6.93984279 10.40873798 12.8808932  -1.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.83594765 -6.83984279 10.46873798 12.9308932  -1.83244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.74594765 -6.81984279 10.52873798 12.9808932  -1.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.67594765 -6.79984279 10.58873798 13.0608932  -1.83244201]]]\n",
      "loss:    [0.09]\n",
      "weights: [[[-7.41594765 -6.74984279 10.79873798 13.1408932  -1.83244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-7.82594765 -7.00984279 10.54873798 13.0108932  -1.93244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.73594765 -6.98984279 10.60873798 13.0608932  -1.93244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.66594765 -6.96984279 10.66873798 13.1408932  -1.93244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.39594765 -6.93984279 10.87873798 13.2008932  -1.93244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-7.88594765 -7.16984279 10.50873798 13.0908932  -2.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.85594765 -7.06984279 10.56873798 13.1408932  -2.03244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.76594765 -7.04984279 10.62873798 13.1908932  -2.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.69594765 -7.02984279 10.68873798 13.2708932  -2.03244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.42594765 -6.99984279 10.89873798 13.3308932  -2.03244201]]]\n",
      "loss:    [0.2]\n",
      "weights: [[[-7.83594765 -7.25984279 10.64873798 13.2008932  -2.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.80594765 -7.15984279 10.70873798 13.2508932  -2.13244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.73594765 -7.13984279 10.76873798 13.3308932  -2.13244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.56594765 -7.12984279 10.87873798 13.4108932  -2.13244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-7.99594765 -7.37984279 10.58873798 13.3108932  -2.23244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-7.85594765 -7.40984279 10.73873798 13.3108932  -2.23244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.82594765 -7.30984279 10.79873798 13.3608932  -2.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.75594765 -7.28984279 10.85873798 13.4408932  -2.23244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-7.58594765 -7.27984279 10.96873798 13.5208932  -2.23244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.01594765 -7.52984279 10.67873798 13.4208932  -2.33244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-7.95594765 -7.52984279 10.70873798 13.4408932  -2.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.92594765 -7.42984279 10.76873798 13.4908932  -2.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.89594765 -7.32984279 10.82873798 13.5408932  -2.33244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.82594765 -7.30984279 10.88873798 13.6208932  -2.33244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.65594765 -7.29984279 10.99873798 13.7008932  -2.33244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.08594765 -7.54984279 10.70873798 13.6008932  -2.43244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-7.94594765 -7.57984279 10.85873798 13.6008932  -2.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.91594765 -7.47984279 10.91873798 13.6508932  -2.43244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.84594765 -7.45984279 10.97873798 13.7308932  -2.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.67594765 -7.44984279 11.08873798 13.8108932  -2.43244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.10594765 -7.69984279 10.79873798 13.7108932  -2.53244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-7.96594765 -7.72984279 10.94873798 13.7108932  -2.53244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.93594765 -7.62984279 11.00873798 13.7608932  -2.53244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.86594765 -7.60984279 11.06873798 13.8408932  -2.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.69594765 -7.59984279 11.17873798 13.9208932  -2.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.12594765 -7.84984279 10.88873798 13.8208932  -2.63244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.06594765 -7.84984279 10.91873798 13.8408932  -2.63244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.00594765 -7.84984279 10.94873798 13.8608932  -2.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.97594765 -7.74984279 11.00873798 13.9108932  -2.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-7.96594765 -7.64984279 11.06873798 13.9908932  -2.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.89594765 -7.62984279 11.12873798 14.0708932  -2.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.62594765 -7.59984279 11.33873798 14.1308932  -2.63244201]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-8.11594765 -7.82984279 10.96873798 14.0208932  -2.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.08594765 -7.72984279 11.02873798 14.0708932  -2.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.05594765 -7.62984279 11.08873798 14.1208932  -2.73244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-7.98594765 -7.60984279 11.14873798 14.2008932  -2.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.81594765 -7.59984279 11.25873798 14.2808932  -2.73244201]]]\n",
      "loss:    [0.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[[-8.24594765 -7.84984279 10.96873798 14.1808932  -2.83244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.18594765 -7.84984279 10.99873798 14.2008932  -2.83244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.12594765 -7.84984279 11.02873798 14.2208932  -2.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.09594765 -7.74984279 11.08873798 14.2708932  -2.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.08594765 -7.64984279 11.14873798 14.3508932  -2.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.01594765 -7.62984279 11.20873798 14.4308932  -2.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.74594765 -7.59984279 11.41873798 14.4908932  -2.83244201]]]\n",
      "loss:    [0.16]\n",
      "weights: [[[-8.23594765 -7.82984279 11.04873798 14.3808932  -2.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.20594765 -7.72984279 11.10873798 14.4308932  -2.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.17594765 -7.62984279 11.16873798 14.4808932  -2.93244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.10594765 -7.60984279 11.22873798 14.5608932  -2.93244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.83594765 -7.57984279 11.43873798 14.6208932  -2.93244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.32594765 -7.80984279 11.06873798 14.5108932  -3.03244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.26594765 -7.80984279 11.09873798 14.5308932  -3.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.23594765 -7.70984279 11.15873798 14.5808932  -3.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.22594765 -7.60984279 11.21873798 14.6608932  -3.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.15594765 -7.58984279 11.27873798 14.7408932  -3.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-7.88594765 -7.55984279 11.48873798 14.8008932  -3.03244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-8.37594765 -7.78984279 11.11873798 14.6908932  -3.13244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.31594765 -7.78984279 11.14873798 14.7108932  -3.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.28594765 -7.68984279 11.20873798 14.7608932  -3.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.27594765 -7.58984279 11.26873798 14.8408932  -3.13244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.07594765 -7.53984279 11.40873798 14.9408932  -3.13244201]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-8.50594765 -7.78984279 11.11873798 14.8408932  -3.23244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.44594765 -7.78984279 11.14873798 14.8608932  -3.23244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.38594765 -7.78984279 11.17873798 14.8808932  -3.23244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.35594765 -7.68984279 11.23873798 14.9308932  -3.23244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.34594765 -7.58984279 11.29873798 15.0108932  -3.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.14594765 -7.53984279 11.43873798 15.1108932  -3.23244201]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-8.57594765 -7.78984279 11.14873798 15.0108932  -3.33244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.51594765 -7.78984279 11.17873798 15.0308932  -3.33244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.45594765 -7.78984279 11.20873798 15.0508932  -3.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.42594765 -7.68984279 11.26873798 15.1008932  -3.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.41594765 -7.58984279 11.32873798 15.1808932  -3.33244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.21594765 -7.53984279 11.46873798 15.2808932  -3.33244201]]]\n",
      "loss:    [0.1]\n",
      "weights: [[[-7.95594765 -7.48984279 11.67873798 15.3608932  -3.33244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-8.47594765 -7.61984279 11.33873798 15.2808932  -3.43244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.40594765 -7.59984279 11.39873798 15.3608932  -3.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.23594765 -7.58984279 11.50873798 15.4408932  -3.43244201]]]\n",
      "loss:    [0.11]\n",
      "weights: [[[-7.97594765 -7.53984279 11.71873798 15.5208932  -3.43244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-8.49594765 -7.66984279 11.37873798 15.4408932  -3.53244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.42594765 -7.64984279 11.43873798 15.5208932  -3.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.15594765 -7.61984279 11.64873798 15.5808932  -3.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.64594765 -7.84984279 11.27873798 15.4708932  -3.63244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.58594765 -7.84984279 11.30873798 15.4908932  -3.63244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.52594765 -7.84984279 11.33873798 15.5108932  -3.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.49594765 -7.74984279 11.39873798 15.5608932  -3.63244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.42594765 -7.72984279 11.45873798 15.6408932  -3.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.15594765 -7.69984279 11.66873798 15.7008932  -3.63244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.64594765 -7.92984279 11.29873798 15.5908932  -3.73244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.58594765 -7.92984279 11.32873798 15.6108932  -3.73244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.52594765 -7.92984279 11.35873798 15.6308932  -3.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.49594765 -7.82984279 11.41873798 15.6808932  -3.73244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.42594765 -7.80984279 11.47873798 15.7608932  -3.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.15594765 -7.77984279 11.68873798 15.8208932  -3.73244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.64594765 -8.00984279 11.31873798 15.7108932  -3.83244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.58594765 -8.00984279 11.34873798 15.7308932  -3.83244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.52594765 -8.00984279 11.37873798 15.7508932  -3.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.49594765 -7.90984279 11.43873798 15.8008932  -3.83244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.42594765 -7.88984279 11.49873798 15.8808932  -3.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.15594765 -7.85984279 11.70873798 15.9408932  -3.83244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-8.64594765 -8.08984279 11.33873798 15.8308932  -3.93244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-8.58594765 -8.08984279 11.36873798 15.8508932  -3.93244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-8.52594765 -8.08984279 11.39873798 15.8708932  -3.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.49594765 -7.98984279 11.45873798 15.9208932  -3.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.48594765 -7.88984279 11.51873798 16.0008932  -3.93244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.31594765 -7.87984279 11.62873798 16.0808932  -3.93244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-8.04594765 -7.84984279 11.83873798 16.1408932  -3.93244201]]]\n",
      "loss:    [0.21]\n",
      "weights: [[[-8.56594765 -7.97984279 11.49873798 16.0608932  -4.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.55594765 -7.87984279 11.55873798 16.1408932  -4.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.38594765 -7.86984279 11.66873798 16.2208932  -4.03244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-8.11594765 -7.83984279 11.87873798 16.2808932  -4.03244201]]]\n",
      "loss:    [0.2]\n",
      "weights: [[[-8.63594765 -7.96984279 11.53873798 16.2008932  -4.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.62594765 -7.86984279 11.59873798 16.2808932  -4.13244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.45594765 -7.85984279 11.70873798 16.3608932  -4.13244201]]]\n",
      "loss:    [0.08]\n",
      "weights: [[[-8.18594765 -7.82984279 11.91873798 16.4208932  -4.13244201]]]\n",
      "loss:    [0.2]\n",
      "weights: [[[-8.70594765 -7.95984279 11.57873798 16.3408932  -4.23244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.69594765 -7.85984279 11.63873798 16.4208932  -4.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.52594765 -7.84984279 11.74873798 16.5008932  -4.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.25594765 -7.81984279 11.95873798 16.5608932  -4.23244201]]]\n",
      "loss:    [0.18]\n",
      "weights: [[[-8.77594765 -7.94984279 11.61873798 16.4808932  -4.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.76594765 -7.84984279 11.67873798 16.5608932  -4.33244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.59594765 -7.83984279 11.78873798 16.6408932  -4.33244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.32594765 -7.80984279 11.99873798 16.7008932  -4.33244201]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-8.81594765 -8.03984279 11.62873798 16.5908932  -4.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.78594765 -7.93984279 11.68873798 16.6408932  -4.43244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.58594765 -7.88984279 11.82873798 16.7408932  -4.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.31594765 -7.85984279 12.03873798 16.8008932  -4.43244201]]]\n",
      "loss:    [0.19]\n",
      "weights: [[[-8.83594765 -7.98984279 11.69873798 16.7208932  -4.53244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.82594765 -7.88984279 11.75873798 16.8008932  -4.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.65594765 -7.87984279 11.86873798 16.8808932  -4.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.38594765 -7.84984279 12.07873798 16.9408932  -4.53244201]]]\n",
      "loss:    [0.17]\n",
      "weights: [[[-8.87594765 -8.07984279 11.70873798 16.8308932  -4.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.84594765 -7.97984279 11.76873798 16.8808932  -4.63244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.67594765 -7.96984279 11.87873798 16.9608932  -4.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.40594765 -7.93984279 12.08873798 17.0208932  -4.63244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-8.89594765 -8.16984279 11.71873798 16.9108932  -4.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.86594765 -8.06984279 11.77873798 16.9608932  -4.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.72594765 -7.93984279 11.91873798 17.0608932  -4.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.45594765 -7.90984279 12.12873798 17.1208932  -4.73244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-8.94594765 -8.13984279 11.75873798 17.0108932  -4.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.91594765 -8.03984279 11.81873798 17.0608932  -4.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.77594765 -7.90984279 11.95873798 17.1608932  -4.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.50594765 -7.87984279 12.16873798 17.2208932  -4.83244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-8.99594765 -8.10984279 11.79873798 17.1108932  -4.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.96594765 -8.00984279 11.85873798 17.1608932  -4.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.82594765 -7.87984279 11.99873798 17.2608932  -4.93244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.55594765 -7.84984279 12.20873798 17.3208932  -4.93244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-9.04594765 -8.07984279 11.83873798 17.2108932  -5.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.01594765 -7.97984279 11.89873798 17.2608932  -5.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.87594765 -7.84984279 12.03873798 17.3608932  -5.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.60594765 -7.81984279 12.24873798 17.4208932  -5.03244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-9.09594765 -8.04984279 11.87873798 17.3108932  -5.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.06594765 -7.94984279 11.93873798 17.3608932  -5.13244201]]]\n",
      "loss:    [0.06]\n",
      "weights: [[[-8.89594765 -7.93984279 12.04873798 17.4408932  -5.13244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.62594765 -7.90984279 12.25873798 17.5008932  -5.13244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-9.11594765 -8.13984279 11.88873798 17.3908932  -5.23244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.05594765 -8.13984279 11.91873798 17.4108932  -5.23244201]]]\n",
      "loss:    [0.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[[-8.91594765 -8.00984279 12.05873798 17.5108932  -5.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.64594765 -7.97984279 12.26873798 17.5708932  -5.23244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.13594765 -8.20984279 11.89873798 17.4608932  -5.33244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.07594765 -8.20984279 11.92873798 17.4808932  -5.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.04594765 -8.10984279 11.98873798 17.5308932  -5.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.93594765 -8.01984279 12.09873798 17.6108932  -5.33244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.66594765 -7.98984279 12.30873798 17.6708932  -5.33244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.15594765 -8.21984279 11.93873798 17.5608932  -5.43244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.09594765 -8.21984279 11.96873798 17.5808932  -5.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.08594765 -8.11984279 12.02873798 17.6608932  -5.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.97594765 -8.02984279 12.13873798 17.7408932  -5.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.70594765 -7.99984279 12.34873798 17.8008932  -5.43244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.19594765 -8.22984279 11.97873798 17.6908932  -5.53244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.13594765 -8.22984279 12.00873798 17.7108932  -5.53244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.99594765 -8.09984279 12.14873798 17.8108932  -5.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.72594765 -8.06984279 12.35873798 17.8708932  -5.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.21594765 -8.29984279 11.98873798 17.7608932  -5.63244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.15594765 -8.29984279 12.01873798 17.7808932  -5.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.12594765 -8.19984279 12.07873798 17.8308932  -5.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-8.98594765 -8.06984279 12.21873798 17.9308932  -5.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.71594765 -8.03984279 12.42873798 17.9908932  -5.63244201]]]\n",
      "loss:    [0.14]\n",
      "weights: [[[-9.20594765 -8.26984279 12.05873798 17.8808932  -5.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.17594765 -8.16984279 12.11873798 17.9308932  -5.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.06594765 -8.07984279 12.22873798 18.0108932  -5.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.79594765 -8.04984279 12.43873798 18.0708932  -5.73244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.28594765 -8.27984279 12.06873798 17.9608932  -5.83244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.22594765 -8.27984279 12.09873798 17.9808932  -5.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.19594765 -8.17984279 12.15873798 18.0308932  -5.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.08594765 -8.08984279 12.26873798 18.1108932  -5.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.81594765 -8.05984279 12.47873798 18.1708932  -5.83244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.30594765 -8.28984279 12.10873798 18.0608932  -5.93244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.24594765 -8.28984279 12.13873798 18.0808932  -5.93244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.10594765 -8.15984279 12.27873798 18.1808932  -5.93244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.83594765 -8.12984279 12.48873798 18.2408932  -5.93244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.32594765 -8.35984279 12.11873798 18.1308932  -6.03244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.26594765 -8.35984279 12.14873798 18.1508932  -6.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.23594765 -8.25984279 12.20873798 18.2008932  -6.03244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.12594765 -8.16984279 12.31873798 18.2808932  -6.03244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.85594765 -8.13984279 12.52873798 18.3408932  -6.03244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.34594765 -8.36984279 12.15873798 18.2308932  -6.13244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.28594765 -8.36984279 12.18873798 18.2508932  -6.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.25594765 -8.26984279 12.24873798 18.3008932  -6.13244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.14594765 -8.17984279 12.35873798 18.3808932  -6.13244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.87594765 -8.14984279 12.56873798 18.4408932  -6.13244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.36594765 -8.37984279 12.19873798 18.3308932  -6.23244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.30594765 -8.37984279 12.22873798 18.3508932  -6.23244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.16594765 -8.24984279 12.36873798 18.4508932  -6.23244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.89594765 -8.21984279 12.57873798 18.5108932  -6.23244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.38594765 -8.44984279 12.20873798 18.4008932  -6.33244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.32594765 -8.44984279 12.23873798 18.4208932  -6.33244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.26594765 -8.44984279 12.26873798 18.4408932  -6.33244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.12594765 -8.31984279 12.40873798 18.5408932  -6.33244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.85594765 -8.28984279 12.61873798 18.6008932  -6.33244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.34594765 -8.51984279 12.24873798 18.4908932  -6.43244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.28594765 -8.51984279 12.27873798 18.5108932  -6.43244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.14594765 -8.38984279 12.41873798 18.6108932  -6.43244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.87594765 -8.35984279 12.62873798 18.6708932  -6.43244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.36594765 -8.58984279 12.25873798 18.5608932  -6.53244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.30594765 -8.58984279 12.28873798 18.5808932  -6.53244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.27594765 -8.48984279 12.34873798 18.6308932  -6.53244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.16594765 -8.39984279 12.45873798 18.7108932  -6.53244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.89594765 -8.36984279 12.66873798 18.7708932  -6.53244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.38594765 -8.59984279 12.29873798 18.6608932  -6.63244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.32594765 -8.59984279 12.32873798 18.6808932  -6.63244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.18594765 -8.46984279 12.46873798 18.7808932  -6.63244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.91594765 -8.43984279 12.67873798 18.8408932  -6.63244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.40594765 -8.66984279 12.30873798 18.7308932  -6.73244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-9.34594765 -8.66984279 12.33873798 18.7508932  -6.73244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.28594765 -8.66984279 12.36873798 18.7708932  -6.73244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.14594765 -8.53984279 12.50873798 18.8708932  -6.73244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.87594765 -8.50984279 12.71873798 18.9308932  -6.73244201]]]\n",
      "loss:    [0.13]\n",
      "weights: [[[-9.36594765 -8.73984279 12.34873798 18.8208932  -6.83244201]]]\n",
      "loss:    [0.04]\n",
      "weights: [[[-9.30594765 -8.73984279 12.37873798 18.8408932  -6.83244201]]]\n",
      "loss:    [0.05]\n",
      "weights: [[[-9.16594765 -8.60984279 12.51873798 18.9408932  -6.83244201]]]\n",
      "loss:    [0.07]\n",
      "weights: [[[-8.89594765 -8.57984279 12.72873798 19.0008932  -6.83244201]]]\n",
      "loss:    [0.12]\n",
      "weights: [[[-9.38594765 -8.80984279 12.35873798 18.8908932  -6.93244201]]]\n",
      "loss:    [0.03]\n",
      "weights: [[[-9.32594765 -8.80984279 12.38873798 18.9108932  -6.93244201]]]\n",
      "loss:    [0.04]\n",
      "\n",
      "target | result: \n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "netw = Netwerk(0, 0, 4, 1, ActivatieFuncties.STEP, .1)\n",
    "\n",
    "X = iris.data[50:]\n",
    "y = np.reshape(iris.target[:100],(-1,1))\n",
    "\n",
    "print(netw._weights)\n",
    "\n",
    "for i in range(500):\n",
    "    netw.update_trivial(X, y, False)\n",
    "    print(\"weights: \" + str(netw._weights))\n",
    "    print(\"loss:    \" + str(netw.loss_MSE(X, y)))\n",
    "   \n",
    "print(\"\\ntarget | result: \")\n",
    "print(np.c_[y, netw.evaluate(X)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa66171",
   "metadata": {},
   "source": [
    "## P3.2: Neuron Unit\n",
    "\n",
    "zoals hieronder te zien werkt de neuron niet met dezelfde weights als de perceptron, als de uitkomst wordt afgerond zit het er echter wel in de buurt. de Sigmoid komt immers niet exact 0 of 1 uit, maar iets daar tussenin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea0be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table AND\n",
      "[0 0] -> [[0.11920292]]\n",
      "[0 1] -> [[0.26894142]]\n",
      "[1 0] -> [[0.26894142]]\n",
      "[1 1] -> [[0.5]]\n",
      "\n",
      "truth table OR\n",
      "[0 0] -> [[0.26894142]]\n",
      "[0 1] -> [[0.5]]\n",
      "[1 0] -> [[0.5]]\n",
      "[1 1] -> [[0.73105858]]\n",
      "\n",
      "truth table NOT\n",
      "[0] -> [[0.5]]\n",
      "[1] -> [[0.26894142]]\n"
     ]
    }
   ],
   "source": [
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.SIGMOID)\n",
    "\n",
    "netw._weights = [np.array([[ 1, 1,-2]])]\n",
    "print(\"truth table AND\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 1, 1,-1]])]\n",
    "print(\"\\ntruth table OR\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[-1, 0]])]\n",
    "print(\"\\ntruth table NOT\")\n",
    "for x in table_in_2:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6dd42",
   "metadata": {},
   "source": [
    "als we de weights zodanig veranderen dat de uitkomst helemaal links of rechts van de sigmoid zit wordt de uitkomst al correcter. ik heb hier voor meervouden van 6 gekozen, gezien σ(6) = 0.99, wat close enough by de 1 zit voor deze doeleinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e8e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth table AND\n",
      "[0 0] -> [[1.52299795e-08]]\n",
      "[0 1] -> [[0.00247262]]\n",
      "[1 0] -> [[0.00247262]]\n",
      "[1 1] -> [[0.99752738]]\n",
      "\n",
      "truth table OR\n",
      "[0 0] -> [[0.00247262]]\n",
      "[0 1] -> [[0.99752738]]\n",
      "[1 0] -> [[0.99752738]]\n",
      "[1 1] -> [[0.99999998]]\n",
      "\n",
      "truth table NOT\n",
      "[0] -> [[0.99752738]]\n",
      "[1] -> [[0.00247262]]\n"
     ]
    }
   ],
   "source": [
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.SIGMOID)\n",
    "\n",
    "netw._weights = [np.array([[ 12, 12, -18]])]\n",
    "print(\"truth table AND\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[ 12, 12, -6]])]\n",
    "print(\"\\ntruth table OR\")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "netw._weights = [np.array([[-12, 6]])]\n",
    "print(\"\\ntruth table NOT\")\n",
    "for x in table_in_2:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5402bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truth table NOR w/ 3 in\n",
      "[0 0 0] -> [[0.99752738]]\n",
      "[0 0 1] -> [[0.00247262]]\n",
      "[0 1 0] -> [[0.00247262]]\n",
      "[0 1 1] -> [[1.52299795e-08]]\n",
      "[1 0 0] -> [[0.00247262]]\n",
      "[1 0 1] -> [[1.52299795e-08]]\n",
      "[1 1 0] -> [[1.52299795e-08]]\n",
      "[1 1 1] -> [[9.35762297e-14]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"434\"\n",
       "            height=\"329\"\n",
       "            src=\"./graphviz_renders/NOR.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18dff574b50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netw._weights = [np.array([[-12,-12,-12, 6]])]\n",
    "print(\"\\ntruth table NOR w/ 3 in\")\n",
    "for x in table_in_8:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2', 'x3']), mindiam=.5, minlen=3, titel='NOR-gate neuron', filename='NOR')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/NOR.gv.bmp')\n",
    "IFrame('./graphviz_renders/NOR.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f00c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truth table half-adder: \n",
      "[0 0] -> [[0.00247262 0.0025469 ]]\n",
      "[0 1] -> [[0.0025469 0.9973766]]\n",
      "[1 0] -> [[0.0025469 0.9973766]]\n",
      "[1 1] -> [[0.9974531 0.0025469]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"927\"\n",
       "            height=\"623\"\n",
       "            src=\"./graphviz_renders/HalfAdder.gv.bmp\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18d83c9a310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netw = Netwerk(0, 0, 0, 0, ActivatieFuncties.SIGMOID)\n",
    "netw._weights = [np.array([[ 12, 12,-18],\n",
    "                           [ 12, 12,-6],\n",
    "                           [-12,-12, 18]]),\n",
    "                 np.array([[ 12, 0, 0,-6],\n",
    "                           [ 0, 12, 12,-18]])]\n",
    "\n",
    "print(\"\\ntruth table half-adder: \")\n",
    "for x in table_in_4:\n",
    "    print(str(x) + \" -> \" + str(netw.evaluate(x)))\n",
    "    \n",
    "g = netw.visualise_network(np.array(['x1', 'x2']), mindiam=1.2, minlen=4, titel='Half-adder neuraal netwerk', filename='HalfAdder')\n",
    "g.render(directory='graphviz_renders', view=False)\n",
    "im = Image.open('./graphviz_renders/HalfAdder.gv.bmp')\n",
    "IFrame('./graphviz_renders/HalfAdder.gv.bmp', width=im.size[0], height=im.size[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
